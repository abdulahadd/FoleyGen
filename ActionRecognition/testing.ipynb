{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 for jumping\n",
    "\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "#load video jumping.mp4 using cv2\n",
    "cap = cv2.VideoCapture('jumping.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "allHogs=[]\n",
    "#create y as a integer list\n",
    "Hogsy=[]\n",
    "Hogsy.append(1)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99629460\n"
     ]
    }
   ],
   "source": [
    "#make currHog a single list\n",
    "print(len(currHog))\n",
    "#flatten the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allHogs.append(currHog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('jumping1.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "Hogsy.append(1)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113400\n"
     ]
    }
   ],
   "source": [
    "print(len(currHog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allHogs.append(currHog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047060\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('jumping2.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "Hogsy.append(1)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n",
    "\n",
    "print(len(currHog))\n",
    "\n",
    "allHogs.append(currHog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619920\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('walking.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "Hogsy.append(2)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n",
    "\n",
    "print(len(currHog))\n",
    "\n",
    "allHogs.append(currHog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169720\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('walking1.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "Hogsy.append(2)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n",
    "\n",
    "print(len(currHog))\n",
    "\n",
    "allHogs.append(currHog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29344140\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('walking2.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "Hogsy.append(2)\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n",
    "\n",
    "print(len(currHog))\n",
    "\n",
    "allHogs.append(currHog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all lists in allHogs the same length, and add 0s to the end of the lists\n",
    "maxlen = max(len(x) for x in allHogs)\n",
    "for x in allHogs:\n",
    "    x.extend([0]*(maxlen-len(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(allHogs, Hogsy, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9495360\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('testing1.mp4')\n",
    "\n",
    "#initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "#create y as a integer list\n",
    "currHog=[]\n",
    "\n",
    "#get frame at every second\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, (cap.get(cv2.CAP_PROP_POS_MSEC)+1000))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame = imutils.resize(frame, width=min(400, frame.shape[1]))\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # detect people in the image\n",
    "    (rects, weights) = hog.detectMultiScale(frame, winStride=(4, 4),\n",
    "        padding=(8, 8), scale=1.05)\n",
    "\n",
    "    # draw the original bounding boxes\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    # apply non-maxima suppression to the bounding boxes using a\n",
    "    # fairly large overlap threshold to try to maintain overlapping\n",
    "    # boxes that are still people\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "    # draw the final bounding boxes\n",
    "    for (xA, yA, xB, yB) in pick:\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "        #crop the image\n",
    "        crop_img = frame[yA:yB, xA:xB]\n",
    "        #calculate the HOG descriptor and append it to the end of the list\n",
    "        FDHOF = hog.compute(crop_img)\n",
    "        currHog.extend(FDHOF)\n",
    "\n",
    "print(len(currHog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model1.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99629460\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "print(loaded_model.n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(currHog) > loaded_model.n_features_in_:\n",
    "    currHog = currHog[:loaded_model.n_features_in_]\n",
    "elif len(currHog) < loaded_model.n_features_in_:\n",
    "    currHog.extend([0]*(loaded_model.n_features_in_-len(currHog)))\n",
    "\n",
    "y_pred = clf.predict([currHog])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walking\n"
     ]
    }
   ],
   "source": [
    "if (y_pred[0] == 1):\n",
    "    print(\"Jumping\")\n",
    "elif (y_pred[0]==2):\n",
    "    print(\"walking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ccb58c476f33ba3e3aee7ac07234ef6b8217ef24ad64d2a7d4fed1a57c1cd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
